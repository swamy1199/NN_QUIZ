{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOf4tP4R/MlIC1alhyvRRXm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swamy1199/NN_QUIZ/blob/main/question2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load the time series dataset\n",
        "data = pd.read_csv('/content/tesla-stock-price.csv')  # Update 'stock_prices.csv' with the path to your dataset\n",
        "\n",
        "# Step 2: Preprocess the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(data[].values.reshape(-1, 1))\n",
        "\n",
        "# Step 3: Split the dataset into training and testing sets\n",
        "train_size = int(len(scaled_data) * 0.8)\n",
        "test_size = len(scaled_data) - train_size\n",
        "train_data, test_data = scaled_data[0:train_size, :], scaled_data[train_size:len(scaled_data), :]\n",
        "\n",
        "# Function to create dataset for LSTM\n",
        "def create_dataset(dataset, time_steps=1):\n",
        "    X, y = [], []\n",
        "    for i in range(len(dataset) - time_steps):\n",
        "        X.append(dataset[i:(i + time_steps), 0])\n",
        "        y.append(dataset[i + time_steps, 0])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "time_steps = 10  # Number of time steps to look back\n",
        "X_train, y_train = create_dataset(train_data, time_steps)\n",
        "X_test, y_test = create_dataset(test_data, time_steps)\n",
        "\n",
        "# Reshape data for LSTM (samples, time steps, features)\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "# Step 4: Build the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
        "model.add(LSTM(units=50))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# Step 5: Train the model\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
        "\n",
        "# Step 6: Evaluate the model\n",
        "train_predictions = model.predict(X_train)\n",
        "test_predictions = model.predict(X_test)\n",
        "\n",
        "# Inverse scaling\n",
        "train_predictions = scaler.inverse_transform(train_predictions)\n",
        "y_train = scaler.inverse_transform([y_train])\n",
        "test_predictions = scaler.inverse_transform(test_predictions)\n",
        "y_test = scaler.inverse_transform([y_test])\n",
        "\n",
        "# Calculate and print metrics\n",
        "train_rmse = np.sqrt(mean_squared_error(y_train[0], train_predictions[:, 0]))\n",
        "test_rmse = np.sqrt(mean_squared_error(y_test[0], test_predictions[:, 0]))\n",
        "train_mae = mean_absolute_error(y_train[0], train_predictions[:, 0])\n",
        "test_mae = mean_absolute_error(y_test[0], test_predictions[:, 0])\n",
        "\n",
        "print('Train RMSE:', train_rmse)\n",
        "print('Test RMSE:', test_rmse)\n",
        "print('Train MAE:', train_mae)\n",
        "print('Test MAE:', test_mae)\n",
        "\n",
        "# Plotting the results\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(y_test.flatten(), label='True')\n",
        "plt.plot(test_predictions.flatten(), label='Predicted')\n",
        "plt.title('Stock Price Prediction')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Stock Price')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "eTpNLxDaVW8I",
        "outputId": "05786a8e-f357-4dda-9023-c3c36c3e152e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax. Perhaps you forgot a comma? (<ipython-input-12-2376f7a57704>, line 14)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-2376f7a57704>\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    scaled_data = scaler.fit_transform(data[].values.reshape(-1, 1))\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
          ]
        }
      ]
    }
  ]
}